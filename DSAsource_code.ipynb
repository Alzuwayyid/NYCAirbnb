{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"FinalProject.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"5mTw97-cgPqd","colab_type":"text"},"source":["# Final project for DSA301"]},{"cell_type":"code","metadata":{"id":"5m9qIINYgPqe","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","\n","import string\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","#import psycopg2\n","#import textatistic\n","import seaborn as sbn\n","from altair import Chart, X, Y, Color, Scale\n","import altair as alt\n","from vega_datasets import data\n","import requests\n","from bs4 import BeautifulSoup\n","import nltk\n","from nltk.corpus import stopwords\n","matplotlib.style.use('ggplot')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9Drrv3EgPqi","colab_type":"text"},"source":["Presented by: Mohammed Alzuwayyid "]},{"cell_type":"markdown","metadata":{"id":"peCFNVvPgPqj","colab_type":"text"},"source":["## Analysis of Data Scientist Job Market in the U.S."]},{"cell_type":"markdown","metadata":{"id":"t2m8EXL5gPqj","colab_type":"text"},"source":["https://www.kaggle.com/sl6149/data-scientist-job-market-in-the-us\n","\n","https://nycdatascience.com/blog/student-works/who-gets-hired-an-outlook-of-the-u-s-data-scientist-job-market-in-2018/"]},{"cell_type":"markdown","metadata":{"id":"rIEgRRoTgPqk","colab_type":"text"},"source":["### Background"]},{"cell_type":"markdown","metadata":{"id":"ueCBpLR7gPqk","colab_type":"text"},"source":["This dataset was scrapped in 8/2018 from Indeed website by Silvia Lu."]},{"cell_type":"markdown","metadata":{"id":"euiuWtdUgPql","colab_type":"text"},"source":["### Objective"]},{"cell_type":"markdown","metadata":{"id":"lav9AendgPql","colab_type":"text"},"source":["My objective of this project is to find in which companies data scientists are in most demand, also how many companies require experience, and what skills are required to pursue a career in Data Science."]},{"cell_type":"markdown","metadata":{"id":"jFO5pj3JgPqm","colab_type":"text"},"source":["## Research Questions"]},{"cell_type":"markdown","metadata":{"id":"wuzJitTDgPqm","colab_type":"text"},"source":["- Which companies hire the most?\n","- How many companies require a related experience?\n","- In which cities are the most demand for jobs?\n","- Which cities contain companies with the highest number of reviews?\n","- How common are other disciplines of Data Science? ex. Machine learning and deep learning."]},{"cell_type":"code","metadata":{"id":"9V-WN69OgPqn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":329},"outputId":"6cf733b0-1291-48a7-c695-447d07be49d7","executionInfo":{"status":"error","timestamp":1592233395012,"user_tz":240,"elapsed":659,"user":{"displayName":"Joaquin Carbonara","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhaJBvj6GmhQhusc_XpzY6d3Bu1jDom7N7jg9siw=s64","userId":"14921749483686740647"}}},"source":["df = pd.read_csv('alldata.csv',encoding = \"ISO-8859-1\").dropna(axis=1, how='all')\n","df.head(6)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-78e4037c1402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alldata.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alldata.csv'"]}]},{"cell_type":"code","metadata":{"id":"salPo19sgPqq","colab_type":"code","colab":{}},"source":["df.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq5OUoKWgPqx","colab_type":"text"},"source":["*** There are 6953 jobs description in this dataset ***"]},{"cell_type":"code","metadata":{"id":"UHpmNFXMgPqx","colab_type":"code","colab":{}},"source":["# Seeing the number of job ads by counting the description\n","num_ads = df.groupby('company', as_index=False)['description'].count()\n","num_ads_ten = num_ads.nlargest(20, 'description') \n","num_ads_ten.rename(columns = {'description':'num_of_Jobs'}, inplace = True) \n","\n","cm = sns.light_palette(\"red\", as_cmap=True)\n"," \n","num_ads_ten.style.background_gradient(cmap='viridis')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q7WmdWw3gPq0","colab_type":"text"},"source":["*** Here we can see the number of jobs for the top 20 companies ***"]},{"cell_type":"code","metadata":{"id":"Db8UrZeJgPq1","colab_type":"code","colab":{}},"source":["alt.Chart(num_ads_ten).mark_bar().encode(x='description',y='company:N')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guGQ4FNmgPq4","colab_type":"text"},"source":["The chart show the number of jobs in Data Science for the top 20 companies "]},{"cell_type":"code","metadata":{"id":"JV7OaAlmgPq4","colab_type":"code","colab":{}},"source":["#This code will look for the times 'experience' and '1-10+ was mentioned\n","years_list = ['1+','2+','3+','4+','5+','6+','7+','8+','9+','10+']\n","experience = df.groupby('company', as_index=False)['description'].sum()\n","\n","experience['experience'] = experience.description.str.count('experience')\n","#This will create #10 columns of the number of experience\n","for year in years_list:\n","    experience[year] = experience.description.str.count(year)\n","\n","experience.drop(experience.columns[1], axis = 1, inplace = True) \n","temp_colmuns = experience.nlargest(20, 'experience')\n","cm = sns.light_palette(\"red\", as_cmap=True)\n"," \n","temp_colmuns.style.background_gradient(cmap='viridis')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bfMw3304gPq7","colab_type":"code","colab":{}},"source":["experience.sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pEbbSevBgPq9","colab_type":"text"},"source":["***This schedule shows how many times numbers of experiences were mentioned in job ads\\\n"," also, by using sum() function we can see that most jobs require 1-5 years of expierence***"]},{"cell_type":"code","metadata":{"id":"Iz4dchCZgPq9","colab_type":"code","colab":{}},"source":["# The code here will clean the data by removing all strings after comma in the location column\n","df['location'].to_string() \n","df = df[df['location'].notna()]\n","\n","def removeAfterComma(string):\n","    return string.split(',')[0].strip()\n","df['location'] = df['location'].apply(removeAfterComma)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSY3elaKgPq_","colab_type":"code","colab":{}},"source":["#This code will count the total number of jobs in each city\n","alt.data_transformers.enable('csv')\n","\n","cities = df.groupby('location', as_index=False)['company'].count()\n","largest_cities = cities.nlargest(20, 'company') \n","largest_cities\n","\n","alt.Chart(largest_cities).mark_bar().encode(\n","    x='company',\n","    y='location',\n","    color='location',\n","    tooltip='company',\n","    order=alt.Order(\n","      # Sort the segments of the bars by this field\n","      'company',\n","      sort='ascending'\n","    )\n",").properties(\n","    width=500,\n","    height=500,\n","    title='Number of companies in each city'\n",")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G8xr1-NkgPrC","colab_type":"text"},"source":["**This chart shows the top 20 cities based on the jobs number, and we can notice that New York is the highest** "]},{"cell_type":"code","metadata":{"id":"DKYLAJ6UgPrD","colab_type":"code","colab":{}},"source":["2\n","alt.Chart(most_rev).mark_bar().encode(\n","    x='reviews',\n","    y='location',\n","    color='location',\n","    tooltip='reviews',\n","    order=alt.Order(\n","      # Sort the segments of the bars by this field\n","      'reviews',\n","      sort='ascending'\n","    )\n",").properties(\n","    width=500,\n","    height=500,\n","    title='Cities with most number of reviews'\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYsGDu-igPrF","colab_type":"text"},"source":["**The chart shows the top 20 cities with most reviews, we can see that Seattle is a bit higher than New York in the total number of reviews**"]},{"cell_type":"code","metadata":{"id":"y6GgjOrggPrG","colab_type":"code","colab":{}},"source":["desc_list = ['Data Scientist','Machine Learning','Data Engineer','Deep Learning','Computer Vision','Data Analyst','Software Engineer','Business Intelligence','Bioinformatic','Business Analyst','Big Data','Artificial Intelligence']\n","\n","\n","\n","\n","jobs_role = df.groupby('company', as_index=False)['position'].sum()\n","jobs_role['Data_word'] = jobs_role.position.str.count('Data')\n","\n","for role in desc_list:\n","    jobs_role[role] = jobs_role.position.str.count(role)\n","\n","jobs_role.drop(jobs_role.columns[1], axis = 1, inplace = True) \n","temp_colmuns = jobs_role.nlargest(20, 'Data_word')\n","cm = sns.light_palette(\"red\", as_cmap=True)\n"," \n","temp_colmuns.style.background_gradient(cmap='viridis')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"atjoXcYqgPrI","colab_type":"code","colab":{}},"source":["jobs_role.sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SeGBQU76gPrK","colab_type":"text"},"source":["**Here we see the demand for other Data Science disciplines, and we can safely say that Machine Learning is the most discipline in demand by the recruiters**"]},{"cell_type":"code","metadata":{"id":"JQV3SsBMgPrL","colab_type":"code","colab":{}},"source":["desc_list = ['SQL','Python','Hadoop','NLP','Java','C#','MATLAB','Azure','AWS','PHP','Scikit-Learn','TensorFlow','PyTorch','Keras','Excel','Scala']\n","\n","\n","jobs_role = df.groupby('company', as_index=False)['description'].sum()\n","\n","for role in desc_list:\n","    jobs_role[role] = jobs_role.description.str.count(role)\n","\n","jobs_role.drop(jobs_role.columns[1], axis = 1, inplace = True) \n","temp_colmuns = jobs_role.nlargest(20, 'Python')\n","cm = sns.light_palette(\"red\", as_cmap=True)\n"," \n","temp_colmuns.style.background_gradient(cmap='viridis')\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zi_rrtczgPrN","colab_type":"code","colab":{}},"source":["jobs_role.sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIIesmHfgPrQ","colab_type":"text"},"source":["**Here are the most common skills and tools in the Data Science world, Excel along with SQL and Python are must-have skills, Hadoop is the highest framework for Big-data analytics, and Amazon Web Services required by many companies who process their data in the cloud. For the Mechine Learning, most companies require a knowledge using TensorFlow**"]},{"cell_type":"code","metadata":{"id":"deWbQHRUgPrR","colab_type":"code","colab":{}},"source":["desc_list = [\"Bachelor\",\"Master\",\"PhD\"]\n","\n","\n","jobs_role = df.groupby('company', as_index=False)['description'].sum()\n","\n","for role in desc_list:\n","    jobs_role[role] = jobs_role.description.str.count(role)\n","    \n","jobs_role.drop(jobs_role.columns[1], axis = 1, inplace = True) \n","temp_colmuns = jobs_role.nlargest(20, 'Bachelor')\n","cm = sns.light_palette(\"red\", as_cmap=True)\n"," \n","temp_colmuns.style.background_gradient(cmap='viridis')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cf5iYFOmgPrT","colab_type":"code","colab":{}},"source":["jobs_role.sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"46wkP1fIgPrV","colab_type":"text"},"source":["**Although the Bachelor's degree is the most in-demand degree, the Ph.D number is still high compared to the number of jobs, given that many companies consider them overqualified for some technical jobs like data analyst, but since other disciplines in Data Science like Big Data analytics and Machine Learning require advanced skills, most companies prefer higher degrees.**"]},{"cell_type":"code","metadata":{"id":"eA4jcHfEgPrV","colab_type":"code","colab":{}},"source":["desc_list = [\"Computer Science\",\"Engineering\",\"Mathematics\",\"Statistics\",\"Data Science\",\"Art\",'Economics']\n","\n","\n","jobs_role = df.groupby('company', as_index=False)['description'].sum()\n","\n","for role in desc_list:\n","    jobs_role[role] = jobs_role.description.str.count(role)\n","    \n","jobs_role.drop(jobs_role.columns[1], axis = 1, inplace = True) \n","temp_colmuns = jobs_role.nlargest(20, 'Computer Science')\n","cm = sns.light_palette(\"red\", as_cmap=True)\n"," \n","temp_colmuns.style.background_gradient(cmap='viridis')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zlLVFTggPrX","colab_type":"code","colab":{}},"source":["jobs_role.sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7RULfisgPrZ","colab_type":"text"},"source":["**Here we can see that STEM majors are the most in-demand majors in Data Science jobs, with Computer Science major being the highest.**"]},{"cell_type":"markdown","metadata":{"id":"qj5wuhJZgPra","colab_type":"text"},"source":["## Conclusions"]},{"cell_type":"markdown","metadata":{"id":"crY9MqE_gPra","colab_type":"text"},"source":["**Data Science is a fast-growing field, and not exclusive to a specific major as the data have proven to us, but people with a STEM major is most likely to get hired. Although most fancy Software engineering and IT jobs are in San Francisco, Data Science jobs on the other hand are mostly located in New York and Seattle.**\n","\n","**There are many tools in the Data Science world and job seekers do not need to learn all of them, however, Python and SQL are required since other frameworks require these two languages** "]},{"cell_type":"code","metadata":{"id":"rSHNOjySgPra","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}